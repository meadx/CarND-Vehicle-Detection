{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection\n",
    "### by Kilian Muelken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Code Cell 1: necessary imports for the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from skimage.feature import hog\n",
    "from moviepy.editor import VideoFileClip\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.externals import joblib\n",
    "import copy\n",
    "from scipy.ndimage.measurements import label\n",
    "from random import randint\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Part 1: Vehicle detection functions\n",
    "*Functions for the vehicle Detection*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1: Common functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Code Cell ?: Calculate sliding windows\n",
    "**Input:** image, start and stop positions in both x and y, window size (x and y dimensions),  and overlap fraction (for both x and y)<br>\n",
    "**Output:** List of sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcSlideWindows(img, xy_window, xy_overlap, x_start, x_stop, y_start, y_stop):\n",
    "        \n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_stop - x_start\n",
    "    yspan = y_stop - y_start\n",
    "    \n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    \n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    \n",
    "    # Initialize a list to append window positions to\n",
    "    slidingWindows = []\n",
    "    \n",
    "    # Loop through finding x and y window positions\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start\n",
    "            endy = starty + xy_window[1]\n",
    "            \n",
    "            # Append window position to list\n",
    "            slidingWindows.append(((startx, starty), (endx, endy)))\n",
    "    \n",
    "    # Return the list of windows\n",
    "    return slidingWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Code Cell ?: Plot and save images\n",
    "**Input:** list of images<br>\n",
    "**Output:** plots and saves images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImage(imgs, save=False):\n",
    "    # check if imgs is a list\n",
    "    imglist = []\n",
    "    \n",
    "    if isinstance(imgs, list):\n",
    "        imglist = imgs\n",
    "    else:\n",
    "        imglist.append(imgs)\n",
    "        \n",
    "    n_img = len(imglist)\n",
    "    \n",
    "    plt.figure(figsize=(20,5))\n",
    "    \n",
    "    for i in range(n_img):\n",
    "        # plot image\n",
    "        n_plot = 101 + n_img*10 + i\n",
    "        plt.subplot(n_plot) # source: https://stackoverflow.com/questions/35692507/plot-several-image-files-in-matplotlib-subplots\n",
    "        plt.imshow(imglist[i])\n",
    "        \n",
    "        # save image if save=true\n",
    "        if save:\n",
    "            #img_BGR = cv2.cvtColor(img_list[i],cv2.COLOR_RGB2BGR)\n",
    "            img_name = 'image_'+time.strftime('%m_%Y_%H_%M_%S')+'.jpg'\n",
    "            mpimg.imsave('output_images/'+img_name, imglist[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Code Cell ?: Draw bounding boxes\n",
    "**Input:** image to draw the boxes, position and size of the boxes<br>\n",
    "**Output:** image with boxes drawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBoxes(img, bboxes, color = (0, 0, 255), thick = 6):\n",
    "    #color = (0, 0, 255) # Color of the boxes is blue\n",
    "    #thick = 6  # thickness of the boxes\n",
    "    \n",
    "    img_boxes = np.copy(img) # Make a copy of the image\n",
    "    \n",
    "    for bbox in bboxes: # Iterate through the bounding boxes\n",
    "        cv2.rectangle(img_boxes, bbox[0], bbox[1], color, thick) # Draw a rectangle given bbox coordinates\n",
    "    \n",
    "    return img_boxes # return the image with boxes drawn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell ?: Read test images\n",
    "**Input:** path of the test images<br>\n",
    "**Output:** images with marked detected vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImages(path):\n",
    "    images = []\n",
    "    images_list = glob.glob(path) # Make a list of calibration images\n",
    "\n",
    "    # Step through the list, read test images and convert them to RGB\n",
    "    for fname in images_list:\n",
    "        img = cv2.imread(fname)\n",
    "        rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        images.append(rgb)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Code Cell ?: Search for positive matches in windows\n",
    "*Uses extractFeatures()*\n",
    "**Input:** Image, Silde windows, Classifier, Scaler<br>\n",
    "**Output:** positive matches in windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSearchWindows(window, windows):\n",
    "    sorround_windows = []\n",
    "    diff = 4\n",
    "    sorround_windows.append(((window[0][0]-diff, window[0][1]), (window[1][0]-diff, window[1][1]))) # left window\n",
    "    #sorround_windows.append(((window[0][0], window[0][1]-diff), (window[1][0], window[1][1]-diff))) # upper window\n",
    "    sorround_windows.append(((window[0][0]+diff, window[0][1]), (window[1][0]+diff, window[1][1]))) # right window\n",
    "    #sorround_windows.append(((window[0][0], window[0][1]+diff), (window[1][0], window[1][1]+diff))) # lower window\n",
    "    \n",
    "    new_windows = []\n",
    "    for sorround_window in sorround_windows:\n",
    "        if sorround_window not in windows:\n",
    "            new_windows.append(sorround_window)\n",
    "        \n",
    "    return new_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchPositiveWindows(img, windows, clf, scaler):\n",
    "    \n",
    "    # Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    \n",
    "    # Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        # Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))\n",
    "        \n",
    "        # Extract features for that window using single_img_features()\n",
    "        features = extractFeatures(test_img)\n",
    "        \n",
    "        # Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        \n",
    "        # Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        \n",
    "        # If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            windows.extend(addSearchWindows(window, windows))\n",
    "            on_windows.append(window)\n",
    "            \n",
    "    # Return windows for positive detections\n",
    "    return on_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Code Cell ?: Find and merge mulitple detections\n",
    "**Input:** Detected windows with cars<br>\n",
    "**Output:** windows with merged multiple detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addHeat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # normalize heatmap\n",
    "    max_heat = heatmap.max()\n",
    "    if max_heat < 4:\n",
    "        max_heat = 4\n",
    "    heatmap /= max_heat\n",
    "        \n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "\n",
    "\n",
    "def getbboxes(labels):\n",
    "    bboxes = []\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        \n",
    "        bboxes.append(bbox)\n",
    "\n",
    "    # Return the bboxes\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "        \n",
    "def multipleDetections(image, windows):\n",
    "    threshold = 0.1\n",
    "    \n",
    "    new_heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    \n",
    "    # define a map to add the heat\n",
    "    if ('heatmap' not in globals()):\n",
    "        heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    \n",
    "    # add new heat to the map\n",
    "    new_heatmap = addHeat(new_heatmap, windows)\n",
    "        \n",
    "    # calculate average with old heat\n",
    "    heatmap = (new_heatmap + 2*heatmap) / 3.0\n",
    "    \n",
    "    # reduce heat less than threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    \n",
    "    # detect cars on image\n",
    "    labels = label(heatmap)\n",
    "    \n",
    "    # get boxes around the detected cars\n",
    "    windows_final = getbboxes(labels)\n",
    "    \n",
    "    # draw boxes on the image\n",
    "    image_final = drawBoxes(image, windows_final)\n",
    "    \n",
    "    return image_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Part 1.2: Feature functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Code Cell ?: Compute HOG features\n",
    "**Input:** Image<br>\n",
    "**Output:** HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hogFeatures(img):\n",
    "    orientations = 9\n",
    "    pix_per_cell = 8\n",
    "    pixels_per_cell=(pix_per_cell, pix_per_cell)\n",
    "    cell_per_block = 2\n",
    "    cells_per_block=(cell_per_block, cell_per_block)\n",
    "    visualise = False\n",
    "    feature_vector = False # was True!!\n",
    "    hog_channel = 'ALL'\n",
    "    \n",
    "    if hog_channel == 'ch':\n",
    "        features = hog(img, orientations=orientations, \n",
    "                    pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                    cells_per_block=(cell_per_block, cell_per_block), \n",
    "                    block_norm= 'L2-Hys',\n",
    "                    transform_sqrt=True, \n",
    "                    visualise=visualise, feature_vector=feature_vector)\n",
    "    elif hog_channel == 'ALL':\n",
    "        features = []\n",
    "        for channel in range(img.shape[2]):\n",
    "            features_channel = hog(img[:,:,channel], orientations=orientations, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       visualise=visualise, feature_vector=feature_vector)\n",
    "            features.append(features_channel)\n",
    "        features = np.ravel(features)\n",
    "    else:\n",
    "        img_hog = img[:,:,hog_channel]\n",
    "        features = hog(img_hog, orientations=orientations, \n",
    "                    pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                    cells_per_block=(cell_per_block, cell_per_block), \n",
    "                    block_norm= 'L2-Hys',\n",
    "                    transform_sqrt=True, \n",
    "                    visualise=visualise, feature_vector=feature_vector)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Code Cell ?: Compute binned color features \n",
    "**Input:** Image<br>\n",
    "**Output:** binned color features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binSpatial(img):\n",
    "    size=(32, 32)\n",
    "    \n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    \n",
    "    # Return the feature vector\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Code Cell ?: Compute color histogram features \n",
    "**Input:** Image<br>\n",
    "**Output:** binned color features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorHist(img):\n",
    "    nbins=32\n",
    "    bins_range=(0, 256) # NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "        \n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    \n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    \n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Code Cell ?: Extract features \n",
    "*Uses hogFeatures(), binSpatial() and colorHist()*\n",
    "**Input:** Image<br>\n",
    "**Output:** features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(imgs):\n",
    "    color_space = 'YCrCb'\n",
    "    spatial_feat = True\n",
    "    hist_feat  =True\n",
    "    hog_feat = True\n",
    "    \n",
    "    # check if imgs is a list\n",
    "    if isinstance(imgs, list):\n",
    "        imglist = imgs\n",
    "    else:\n",
    "        imglist = []\n",
    "        imglist.append(imgs)\n",
    "        \n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    \n",
    "    for img in imglist:\n",
    "        img_features = []\n",
    "    \n",
    "        # color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "            elif color_space == 'HLS':\n",
    "                    feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        else:\n",
    "            feature_image = np.copy(img) \n",
    "\n",
    "        # Compute binned color features\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = binSpatial(feature_image)\n",
    "            img_features.append(spatial_features)\n",
    "            \n",
    "\n",
    "        # Compute color histogram features\n",
    "        if hist_feat == True:\n",
    "            hist_features = colorHist(feature_image)\n",
    "            img_features.append(hist_features)\n",
    "            \n",
    "\n",
    "        # Compute HOG features\n",
    "        if hog_feat == True:\n",
    "            hog_features = hogFeatures(feature_image)\n",
    "            img_features.append(hog_features)\n",
    "\n",
    "        features.append(np.concatenate(img_features))\n",
    "        \n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Part ?: Training of the Classifier\n",
    "*Training of the Classifier with test images*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell ?: Training Pipeline\n",
    "**Input:** path of the training images<br>\n",
    "**Output:** trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitImages(images):\n",
    "    images_split = []\n",
    "    for image in images:\n",
    "        i = randint(0, 15)\n",
    "        if i == 0:\n",
    "            img = cv2.resize(image[0:image.shape[0]*3//4 , 0:image.shape[1]*3//4 , :], (64,64))\n",
    "            images_split.append(img)\n",
    "        elif i == 1:\n",
    "            img = cv2.resize(image[image.shape[0]//4:image.shape[0] , 0:image.shape[1]*3//4 , :], (64,64))\n",
    "            images_split.append(img)\n",
    "        elif i == 2:\n",
    "            img = cv2.resize(image[0:image.shape[0]*3//4 , image.shape[1]//4:image.shape[1] , :], (64,64))\n",
    "            images_split.append(img)\n",
    "        elif i == 3:\n",
    "            img = cv2.resize(image[image.shape[0]//4:image.shape[0] , image.shape[1]//4:image.shape[1] , :], (64,64))\n",
    "            images_split.append(img)\n",
    "        else:\n",
    "            images_split.append(image)\n",
    "    shuffle(images_split)\n",
    "    return images_split\n",
    "    \n",
    "\n",
    "def trainingPipeline(cars, notcars):\n",
    "    n_cars = len(cars)\n",
    "    n_notcars = len(notcars)\n",
    "    \n",
    "    if n_cars < n_notcars:\n",
    "        notcars = notcars[0:n_cars]\n",
    "    elif n_notcars < n_cars:\n",
    "        cars = cars[0:n_notcars]\n",
    "    \n",
    "    car_features = extractFeatures(cars)\n",
    "    notcar_features = extractFeatures(notcars)\n",
    "        \n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "    # Split up data into randomized training and test sets\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # Apply the scaler to X\n",
    "    X_train = X_scaler.transform(X_train)\n",
    "    X_test = X_scaler.transform(X_test)\n",
    "    \n",
    "    # Use a linear SVC \n",
    "    svc = LinearSVC()\n",
    "    svc.fit(X_train, y_train)\n",
    "    \n",
    "    # Check the score of the SVC\n",
    "    print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "    \n",
    "    return svc, X_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = False # Set to True for new training\n",
    "\n",
    "if training:\n",
    "    # read train images\n",
    "    notcars = readImages('train_nv/*.png')\n",
    "    cars = readImages('train_v/*.png')\n",
    "    \n",
    "    #notcars = splitImages(notcars)\n",
    "    #cars = splitImages(cars)\n",
    "\n",
    "    clf, scaler = trainingPipeline(cars, notcars)\n",
    "\n",
    "    # save the classifier and scaler to the disk\n",
    "    # source: http://scikit-learn.org/stable/modules/model_persistence.html\n",
    "    joblib.dump(clf, 'clf.pkl')\n",
    "    joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the classifier and scaler\n",
    "# source: http://scikit-learn.org/stable/modules/model_persistence.html\n",
    "clf = joblib.load('clf.pkl')\n",
    "scaler = joblib.load('scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Part ?: Testing\n",
    "*Test of the Classifier with test images and test video*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Code Cell ?: Image Testing Pipeline\n",
    "*Test of the Classifier with test images*<br>\n",
    "**Input:** path of the test images<br>\n",
    "**Output:** images with marked detected vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    global heatmap # detected windows from the last image\n",
    "    \n",
    "    image = np.copy(img) # Make a copy of the image\n",
    "    \n",
    "    # calculate the searching windows\n",
    "    slide_windows = calcSlideWindows(image, (32, 32), (0.5, 0.5), 320, 960, 400, 464)\n",
    "    slide_windows.extend(calcSlideWindows(image, (64, 64), (0.5, 0.5), 128, 1152, 400, 464))\n",
    "    slide_windows.extend(calcSlideWindows(image, (96, 96), (0.5, 0.5), 96, 1184, 400, 496))\n",
    "    slide_windows.extend(calcSlideWindows(image, (128, 128), (0.5, 0.5), 64, 1216, 400, 528))\n",
    "    slide_windows.extend(calcSlideWindows(image, (160, 160), (0.5, 0.5), 80, 1200, 400, 560))\n",
    "    slide_windows.extend(calcSlideWindows(image, (192, 192), (0.5, 0.5), 16, 1264, 400, 592))\n",
    "    slide_windows.extend(calcSlideWindows(image, (256, 256), (0.5, 0.5), 0, 1280, 400, 656))\n",
    "    \n",
    "    # find positive matches in searching windows\n",
    "    car_windows = searchPositiveWindows(image, slide_windows, clf, scaler)\n",
    "\n",
    "    # merge multiple detections\n",
    "    image_cars = multipleDetections(image, car_windows)\n",
    "        \n",
    "    return image_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read test images\n",
    "if False:\n",
    "    test_images = readImages('test_images/*.jpg')\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for test_image in test_images:\n",
    "        # pipeline\n",
    "        test_image_detected = pipeline(test_image)\n",
    "        images.append(test_image_detected)\n",
    "\n",
    "    plotImage(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotImage(images[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell ?: Detect vehicles on video\n",
    "**Input:** name of the test video<br>\n",
    "**Output:** video with marked detected vehicles will be written in current folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectVehicles(video_file_name):\n",
    "    clip = VideoFileClip(video_file_name+'.mp4')\n",
    "    #clip = VideoFileClip(video_file_name+'.mp4').subclip(20,25)\n",
    "    video_clip = clip.fl_image(pipeline)\n",
    "    %time video_clip.write_videofile(video_file_name+'_with_detected_vehicles.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_with_detected_vehicles.mp4\n",
      "[MoviePy] Writing video project_video_with_detected_vehicles.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [27:42<00:01,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_with_detected_vehicles.mp4 \n",
      "\n",
      "Wall time: 27min 42s\n"
     ]
    }
   ],
   "source": [
    "detectVehicles('project_video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
